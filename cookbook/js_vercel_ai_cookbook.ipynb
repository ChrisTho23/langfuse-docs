{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed99590b",
   "metadata": {},
   "source": [
    "# Cookbook: Vercel AI (JS/TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bb073",
   "metadata": {},
   "source": [
    "This is a cookbook with an end-to-end example on how to use Langfuse within the Vercel AI framework (JS/TS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fc726",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26910f18",
   "metadata": {},
   "source": [
    "Initialize Langfuse with your API keys from the project settings in the Langfuse UI and add them to your environment. As we will use OpenAI LLMs for this example, we also want to configure an OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d409b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Langfuse } from \"npm:langfuse\"\n",
    "import { Configuration, OpenAIApi } from \"npm:openai-edge\";\n",
    "\n",
    "const langfuse = new Langfuse({\n",
    "  publicKey: \"\",\n",
    "  secretKey: \"\",\n",
    "  baseUrl: \"https://cloud.langfuse.com\",\n",
    "});\n",
    "\n",
    "const openAIconfig = new Configuration({\n",
    "  apiKey: \"\",\n",
    "});\n",
    "const openai = new OpenAIApi(openAIconfig);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476294b8",
   "metadata": {},
   "source": [
    "## Vercel AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc8f0e",
   "metadata": {},
   "source": [
    "**Vercel AI:**\n",
    "Vercel is a cloud platform for frontend development that offers global deployment, streamlined scaling, and enhanced security for building and delivering fast, personalized web experiences.\n",
    "\n",
    "**Our Example:**\n",
    "In our example, we will use `OpenAIStream` to efficiently process and stream responses from OpenAI's models, and `StreamingTextResponse` to seamlessly deliver these AI-generated responses as HTTP streams to users, simulating the real-time interaction capabilities of a Vercel-hosted application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5f4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { OpenAIStream, StreamingTextResponse } from \"npm:ai\";\n",
    "\n",
    "// edge rutime to use caching and execute in closest data center\n",
    "export const runtime = 'edge';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f06cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Example application simulating a QA chat bot using Langfuse and Vercel AI framework. \n",
    " * \n",
    " * Creates trace, retrieves a pre-saved prompt template, generates answer, and scores generation.\n",
    " * Utilizes OpenAI API for chat completion.\n",
    " *\n",
    " * @param {Request} req - The request object, containing session information, user ID, and messages.\n",
    " * @param {Response} res - The response object used to send back the processed data.\n",
    " * @returns {StreamingTextResponse} - A streamed response containing the output of the OpenAI model.\n",
    " */\n",
    "export default async function handler(req: Request, res: Response) {\n",
    "    // initialize Langfuse \n",
    "    const trace = langfuse.trace({\n",
    "        name: \"QA\",\n",
    "        sessionId: req.sessionId,\n",
    "        userId: req.userId,\n",
    "    });\n",
    "    \n",
    "    // Format incoming messages for OpenAI API\n",
    "    const messages = req.messages\n",
    "    const openAiMessages = messages.map(({ content, role }) => ({\n",
    "        content,\n",
    "        role: role,\n",
    "    }));\n",
    "    \n",
    "    // get last message\n",
    "    const sanitizedQuery = messages[messages.length - 1].content.trim();\n",
    "\n",
    "    trace.update({\n",
    "        input: sanitizedQuery,\n",
    "    });\n",
    "    \n",
    "    const promptName = req.promptName\n",
    "    \n",
    "    const promptSpan = trace.span({\n",
    "        name: \"fetch-prompt-from-langfuse\",\n",
    "        input: {\n",
    "            promptName,\n",
    "        },\n",
    "    });\n",
    "    \n",
    "    // retrieve Langfuse prompt template with promptName\n",
    "    const prompt = await langfuse.getPrompt(promptName);\n",
    "    \n",
    "    const promptTemplate = prompt.prompt\n",
    "  \n",
    "    promptSpan.end({\n",
    "        output: { \n",
    "            promptTemplate,\n",
    "        },\n",
    "    });\n",
    "    \n",
    "    // merge prompt template and user input\n",
    "    const assembledMessages = [\n",
    "        {\n",
    "            role: \"system\",\n",
    "            content: promptTemplate,\n",
    "        },\n",
    "        ...openAiMessages,\n",
    "    ];\n",
    "      \n",
    "    const generation = trace.generation({\n",
    "        name: \"generation\",\n",
    "        input: assembledMessages as any,\n",
    "        model: \"gpt-3.5-turbo\",\n",
    "        prompt,\n",
    "    });\n",
    "\n",
    "    const response = await openai.createChatCompletion({\n",
    "        model: \"gpt-3.5-turbo\",\n",
    "        stream: true,\n",
    "        messages: assembledMessages,\n",
    "    });\n",
    "    \n",
    "    // Stream the response from OpenAI\n",
    "    const stream = OpenAIStream(response, {\n",
    "        onStart: () => {\n",
    "            generation.update({\n",
    "                completionStartTime: new Date(),\n",
    "            });\n",
    "        },\n",
    "        onCompletion: async (completion) => {\n",
    "            generation.end({\n",
    "                output: completion,\n",
    "                level: completion.includes(\"I don't know how to help with that\")\n",
    "                    ? \"WARNING\"\n",
    "                    : \"DEFAULT\",\n",
    "                statusMessage: completion.includes(\"I don't know how to help with that\")\n",
    "                    ? \"Refused to answer\"\n",
    "                    : undefined,\n",
    "            });\n",
    "            if (!completion.includes(\"I don't know how to help with that\")) {\n",
    "                generation.score({\n",
    "                    name: \"quality\",\n",
    "                    value: 1,\n",
    "                    comment: \"Factually correct\",\n",
    "                });\n",
    "            }\n",
    "        trace.update({\n",
    "            output: completion,\n",
    "        });\n",
    "        await langfuse.shutdownAsync(); // flush Langfuse\n",
    "        },\n",
    "    });\n",
    "\n",
    "    return new StreamingTextResponse(stream, {\n",
    "        headers: {\n",
    "            \"X-Trace-Id\": trace.id,\n",
    "        },\n",
    "    });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5725f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "// sample request to test handler function\n",
    "const mockRequest = {\n",
    "    \"sessionId\": \"testSession\",\n",
    "    \"userId\": \"testUser\",\n",
    "    \"promptName\": \"qa-prompt\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is love?\"\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62be1faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love is a deep feeling of affection and care towards someone or something. It can manifest in many different forms such as romantic love, familial love, or love for friends. Love often involves feelings of warmth, compassion, and a desire to see the other person happy. It's a beautiful and complex emotion that can bring joy and fulfillment to our lives.\n"
     ]
    }
   ],
   "source": [
    "const response = await handler(mockRequest);\n",
    "const data = await response.text();\n",
    "console.log(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a0cc8",
   "metadata": {},
   "source": [
    "## Explore the trace in the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c1f83",
   "metadata": {},
   "source": [
    "https://cloud.langfuse.com/project/clr4qu8qv0000yu4ja339x02u/traces/5cabfef1-54a0-4f52-a0ea-cba0c877a4e4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
